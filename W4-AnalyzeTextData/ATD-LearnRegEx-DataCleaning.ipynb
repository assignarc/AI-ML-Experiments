{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4-U8LXm5bSw"
   },
   "source": [
    "<center><font size=8>Analyzing Text Data - Learners</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DrTOBrYBiCR"
   },
   "source": [
    "# **Installing and Importing the Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8381,
     "status": "ok",
     "timestamp": 1749725935548,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "79D1rXhBAxCs"
   },
   "outputs": [],
   "source": [
    "!pip install pandas==2.2.2 numpy==2.0.2 nltk==3.9.1 scikit-learn==1.6.1   -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1749725940008,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "xhZUQ78gzw8H"
   },
   "outputs": [],
   "source": [
    "# to read and manipulate the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# setting column to the maximum column width as per the data\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJDPhhmvvxJ1"
   },
   "source": [
    "### **Removing special characters from the text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi2fXV6b7fVO"
   },
   "source": [
    "<h2>Why Remove Special Characters in Text Preprocessing?</h2>\n",
    "\n",
    "- Special characters can introduce unnecessary elements, complicating text analysis.\n",
    "\n",
    "- Clean text is simpler to work with and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOdhCu8E8Bij"
   },
   "source": [
    "<h2>How to Implement Special Character Removal in Text Preprocessing?</h2>\n",
    "\n",
    "- We can start by manually replacing unwanted characters like @, #, or punctuation marks with spaces.\n",
    "\n",
    "- String functions like `replace()` help with simple replacements across the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1749725943408,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "0JziXnp3vt_D"
   },
   "outputs": [],
   "source": [
    "text = \"office.aiml.utaustin@mygreatlearning.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749725943422,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "MTJ2ZX3Bvt7k",
    "outputId": "ebc35197-3ddf-4da4-d65d-527042bd8267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'office.aiml.utaustin mygreatlearning.com'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_text1 = text.replace(\"@\", \" \")\n",
    "upd_text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1JE8KwjwfVT"
   },
   "source": [
    "- We can observe that the '@' character has been replaced with a whitespace.\n",
    "- Additionally, there are some punctuation marks in the email address. Let's replace those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1749725943450,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "Rb2OIGakwRvO",
    "outputId": "270094c1-95ad-42f2-ae2c-9a6d942fe5a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'office aiml utaustin mygreatlearning com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_text2 = upd_text1.replace(\".\", \" \")\n",
    "upd_text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkQHhY3dwcfU"
   },
   "source": [
    "- The punctuation marks ('.') are also replaced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSSK3ZoyvuhI"
   },
   "source": [
    "- However, as text become larger and contain various patterns of special characters, manually handling them becomes tedious.\n",
    "\n",
    "- In such cases, we need more flexible methods to efficiently identify and remove multiple patterns at once - this is where advanced tools like regular expressions come in handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OT_43nnO9KgX"
   },
   "source": [
    "<h2>Regular Expressions</h2>\n",
    "\n",
    "- Regular expression, also called regex in short, is a sequence of symbols and characters expressing a string or pattern to be searched for within a longer piece of text.\n",
    "\n",
    "- They enable complex text processing tasks, such as finding, replacing, or removing patterns, making data cleaning more efficient.\n",
    "\n",
    "- Example:\n",
    "    - **Pattern:** `a`\n",
    "    - **Description:** This regex pattern matches the letter \"a\" in any text.\n",
    "    - **Usage:** In the text \"apple pie\", the pattern `a` will match the occurrence of \"a,\" allowing for identification or manipulation of that letter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nMFZrmAxQFU"
   },
   "source": [
    "- Regular expressions are implemented in Python using the `re` library.\n",
    "\n",
    "- It is imported using the statement `import re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1749725943482,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "ta_ayGHjx_ZS"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpDIfg6hWJzm"
   },
   "source": [
    "- Suppose you have a string, and you are interested in adding a character between each of its characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749725943491,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "RTdBFsfFWJzo"
   },
   "outputs": [],
   "source": [
    "string = \"Regular expressions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLCuHg3WWJzo"
   },
   "source": [
    "- This is where the join method comes to rescue.\n",
    "\n",
    "  - The `join()` method takes all characters in a string and joins them into one string with a sepataror.\n",
    "\n",
    "  - A string must be specified as the separator.\n",
    "\n",
    "  - **Syntax :** string.join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1749725943528,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "18e0SPMYEcFd",
    "outputId": "d0a401d6-fddb-4754-bc74-efb650788f85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rspaceespacegspaceuspacelspaceaspacerspace spaceespacexspacepspacerspaceespacesspacesspaceispaceospacenspaces'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'space'.join(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RdxSGBdWJzq"
   },
   "source": [
    "- As we can observe, the string 'space' has been added between each character in the `string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749725943545,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "qNfZNA0dWJzr",
    "outputId": "e8f69d38-b1ad-4f42-f2ab-7c9aa17505d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R e g u l a r   e x p r e s s i o n s'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VldKvFlyWJzs"
   },
   "source": [
    "- As we can observe, a whitespace has been added between each character in the `string`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te9QFde5ARpH"
   },
   "source": [
    "<h2>1. Pattern: [a-z]</h2>\n",
    "<p><strong>Use Case:</strong> Extracting lowercase letters from usernames.</p>\n",
    "<p><strong>Description:</strong> This pattern matches any single lowercase letter from 'a' to 'z'. It can be used to ensure usernames contain only lowercase letters.</p>\n",
    "<pre>\n",
    "pattern = r'[a-z]'\n",
    "# Finding the specified pattern and replacing lowercase characters with a blank string\n",
    "new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83bnDwkPjIXA"
   },
   "source": [
    "- The `r` prefix creates a raw string, preventing Python from interpreting backslashes as escape characters, which is essential when working with regular expressions that often use backslashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuaQfFEd_Win"
   },
   "source": [
    "- [] define a character set, which matches any one character from a specified set of characters inside the brackets.\n",
    "\n",
    "- For example, [abc] will match either a, b, or c in the input text.\n",
    "\n",
    "- If you put a hyphen between characters like [a-z], it matches any character in that range, so [a-z] matches any lowercase letter from a to z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FVlN1PK_YEw"
   },
   "source": [
    "- The `re` library in Python includes many built-in functions, one of which is `re.sub`, used for substituting occurrences of a specified regex pattern in a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bDHSB00B9W9"
   },
   "source": [
    "**```re.sub(pattern, replacement, string)```**\n",
    "\n",
    "This function is used to replace occurrences of a pattern in a string.\n",
    "\n",
    "- **`pattern`:** The regular expression that defines the sequence of characters you want to search for in the string.\n",
    "\n",
    "- **`replacement`:** The string that will replace each occurrence of the pattern found in the original string.\n",
    "\n",
    "- **`string`:** The input string where the search and replacement will occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1749725943563,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "ktFHd3ACAE5M",
    "outputId": "8fe2e140-eec2-4edd-d3f0-8024a20df75a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P      M      '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'[a-z]'\n",
    "replacement = ' '\n",
    "string = 'Python Modules'\n",
    "\n",
    "output = re.sub(pattern,replacement,string)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjdQZugmAXkG"
   },
   "source": [
    "- As expected, the characters [a-z] in the string are replaced with a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkBy3g3Kya9_"
   },
   "source": [
    "- Let's check a simple example of how the above pattern can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749725943613,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "-wwqc_VWiEqm",
    "outputId": "9d147402-7b55-4c3f-8f27-3dc810f0d473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence and Machine Learning\n",
      "A          I                M       L       \n"
     ]
    }
   ],
   "source": [
    "string = \"Artificial Intelligence and Machine Learning\"\n",
    "pattern = r'[a-z]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnTjPvYXyhNG"
   },
   "source": [
    "- As we can observe, the lower case characters in the string contained in the variable `string` have been replaced with a whitespace (and not a blank).\n",
    "\n",
    "- Let's verify the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749725943622,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "h2Dimo_mz2Ub",
    "outputId": "84cbc27c-53de-4c4a-a608-8e0e83a70742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(len(string))\n",
    "print(len(cleaned_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-s0cfUU0H7z"
   },
   "source": [
    "- Since the lower case characters are replaced with a whitespace and whitespace is also a character, the length of the `cleaned_string` remains unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTtq5yKwz6LA"
   },
   "source": [
    "- We can also replace the lower case characters in the string with a blank, i.e., remove those characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749725943629,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "xACvRxuuzOYn",
    "outputId": "fda0e7d5-35d3-45f7-a47f-f3171b57c932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence and Machine Learning\n",
      "A I  M L\n"
     ]
    }
   ],
   "source": [
    "string = \"Artificial Intelligence and Machine Learning\"\n",
    "pattern = r'[a-z]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,'',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1749725943706,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "Rth7uXKj0LEi",
    "outputId": "c334e687-377a-40e6-d916-6468207dd1b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(string))\n",
    "print(len(cleaned_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_KlZx3C0MXv"
   },
   "source": [
    "- Since the lowercase characters are replaced with a blank space, and a blank space is a character of zero length, the length of the `cleaned_string` changed and was reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSWSeI-hCZor"
   },
   "source": [
    "- As we can observe, the lowercase letters have been replaced with a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b02RfCwDPAJ"
   },
   "source": [
    "<h2>2. Pattern: [A-Z]</h2>\n",
    "<p><strong>Use Case:</strong> Validating employee IDs that start with uppercase letters.</p>\n",
    "<p><strong>Description:</strong> This pattern matches any single uppercase letter from 'A' to 'Z'. It can be used to check that employee IDs start with a capital letter.</p>\n",
    "<pre>\n",
    "pattern = r'[A-Z]'\n",
    "# Finding the specified pattern and replacing uppercase characters with a blank string\n",
    "new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1749725943708,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "qh6LnFwFixVG",
    "outputId": "39a81958-4b53-4b5f-d2fe-dc8440a816ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID1230\n",
      "  1230\n"
     ]
    }
   ],
   "source": [
    "string = \"ID1230\"\n",
    "pattern = r'[A-Z]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P77zG6nfCrhu"
   },
   "source": [
    "- As we can observe, the uppercase letters have been replaced with a whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPky7ZWSC1K6"
   },
   "source": [
    "- Every sentence starts with an uppercase letter.\n",
    "- As we can observe, the uppercase characters have been replaced with a whitespace, along with all other uppercase characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjjZESwTDUMN"
   },
   "source": [
    "<h2>3. Pattern: [0-9]</h2>\n",
    "<p><strong>Use Case:</strong> Extracting the template from a string.</p>\n",
    "<p><strong>Description:</strong> This pattern matches any single digit from '0' to '9'.</p>\n",
    "<pre>\n",
    "pattern = r'[0-9]'\n",
    "# Finding the specified pattern and replacing digit characters with a white space\n",
    "new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749725943727,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "B8Jw5lapjhQV",
    "outputId": "54ade449-3e58-425a-c27e-b5e62097eaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderNumber: 12345, TotalAmount: $67.89\n",
      "OrderNumber:      , TotalAmount: $  .  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"OrderNumber: 12345, TotalAmount: $67.89\"\n",
    "pattern = r'[0-9]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53qUS8dbDmGy"
   },
   "source": [
    "- There is a particular template in the string:\n",
    "  - It contains an Order Number and Total Amount with some values.\n",
    "  - If we replace the values with whitespace, we can retrieve the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749725943740,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "Fyv4B8VOjhg8",
    "outputId": "14f4b8a2-4ae1-454d-bc82-4ab90e75c896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature today is 75 degrees Fahrenheit.\n",
      "The temperature today is    degrees Fahrenheit.\n",
      "The temperature today is    degrees Fahrenheit.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"The temperature today is 75 degrees Fahrenheit.\"\n",
    "pattern = r'[0-9]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "other_cleaned_string = re.sub(pattern,' ',string)\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)\n",
    "print(other_cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GVPJws0EDcK"
   },
   "source": [
    "- Imagine there is a simple website that displays the daily temperature in a specific format.\n",
    "  - In the above string, only the temperature value changes while the format remains the same.\n",
    "  - If we replace that value with a whitespace or any other value, we can update the temperature.\n",
    "  - For now, we will retrieve the template alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGRbjl2JFzkN"
   },
   "source": [
    "- As expected the string '1930' has been replaced with a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7En_rvCaDYz_"
   },
   "source": [
    "<h2>4. Pattern: [^]</h2>\n",
    "\n",
    "- The ^ character is used as a negation operator in regular expressions.\n",
    "- Any pattern mentioned after the ^ character will be excluded from consideration.\n",
    "\n",
    "<strong>Use Case:</strong> Removing all non-numeric characters from a string of digits.\n",
    "\n",
    "<strong>Description:</strong> The pattern `[^0-9]` matches any character that is not a digit. It can be used to clean up strings that should only contain numbers.\n",
    "\n",
    "```\n",
    "pattern = r'[^0-9]'\n",
    "# Finding the specified pattern and replacing non-digit characters with a blank string\n",
    "new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1749725943830,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "OxBKUoepkMxJ",
    "outputId": "fbdfe8c0-e14f-4f53-800e-5504e56adc73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderNumber: 12345, TotalAmount: $67.89\n",
      "             12345                67 89\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"OrderNumber: 12345, TotalAmount: $67.89\"\n",
    "pattern = r'[^0-9]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSvfO14EHR85"
   },
   "source": [
    "- In one of the previous examples, we have retrieved the template.\n",
    "  - To retrieve anything apart from the template, we can use the ^ character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1749725943833,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "LATIOL6ekNJi",
    "outputId": "581cdb84-3d68-43d3-9ae9-1db3cb5d5bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature today is 75 degrees Fahrenheit.\n",
      "                         75                    \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"The temperature today is 75 degrees Fahrenheit.\"\n",
    "pattern = r'[^0-9]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnGawEF9HrgQ"
   },
   "source": [
    "- In one of the previous examples, we have retrieved the template.\n",
    "  - To retrieve anything apart from the template, we can use the ^ character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpvxS6heHsey"
   },
   "source": [
    "- As the review contains no digits, all characters have been replaced with whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFRCizPODcwp"
   },
   "source": [
    "<h2>5. Pattern: [^A-Za-z]</h2>\n",
    "<p><strong>Use Case:</strong> Sanitizing input fields to allow only letters.</p>\n",
    "<p><strong>Description:</strong> This pattern matches any character that is not a letter (either uppercase or lowercase). It can be used to sanitize user input in forms to ensure it only contains alphabetic characters.</p>\n",
    "<pre>\n",
    "pattern = r'[^A-Za-z]'\n",
    "# Finding the specified pattern and replacing non-letter characters with a blank string\n",
    "new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1749725943858,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "E-BNlqEnk5i0",
    "outputId": "0c14b6bd-ab69-4925-b48c-7cc6262c6f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "johan123@gmail.com\n",
      "johan    gmail com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"johan123@gmail.com\"\n",
    "pattern = r'[^A-Za-z]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abBTGIFcIFra"
   },
   "source": [
    "- As expected, all characters outside of [A-Za-z] have been replaced with whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1749725943899,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "fMLyqKkWk5tW",
    "outputId": "bf4d9e8b-56d4-4581-eef3-745c6f16d3a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderNumber: 12345, TotalAmount: $67.89\n",
      "OrderNumber         TotalAmount        \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"OrderNumber: 12345, TotalAmount: $67.89\"\n",
    "pattern = r'[^A-Za-z]'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyWP8LQXIaHQ"
   },
   "source": [
    "- As expected, all characters outside of [A-Za-z] have been replaced with whitespace.\n",
    "- Additionally, this is another way to retrieve the template, which was discussed in one of the previous examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI5xp0ojIt5h"
   },
   "source": [
    "- As expected the strings '1900' and '1990' has been replaced with a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1weSAtLBGNIq"
   },
   "source": [
    "<h2>6. Pattern: []+</h2>\n",
    "\n",
    "- The + character is used to indicate that the preceding element must occur one or more times.\n",
    "- Any pattern mentioned before the + character will be matched as long as it appears at least once.\n",
    "\n",
    "**Use Case**: Validating hexadecimal color codes.\n",
    "\n",
    "**Description**: The pattern `[a-fA-F0-9]+` matches one or more characters in the range 'a' to 'f' (lowercase) or 'A' to 'F' (uppercase) or 0-9. It can be used to extract or validate parts of hexadecimal color codes.\n",
    "\n",
    "```\n",
    "pattern = r'[a-fA-F]+'\n",
    "# Finding the specified pattern and replacing non-hexadecimal characters with a blank string\n",
    "new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1749725943923,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "VZ2dGJKflL4y",
    "outputId": "817fde41-093a-45c1-b9f8-91a019aa3cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ff0000 #6a5acd\n",
      "#  # \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"#ff0000 #6a5acd\"\n",
    "pattern = r'[a-fA-F0-9]+'\n",
    "\n",
    "cleaned_string = ''.join(re.sub(pattern,' ',string))\n",
    "\n",
    "print(string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od5KReAKJ3rc"
   },
   "source": [
    "- ##ff0000 and #6a5acd represents colors in hexadecimal format.\n",
    "\n",
    "- The entire string 'ff0000' is matched as a single pattern since + matches one or more characters specified.\n",
    "\n",
    "- Also, the string '6a5acd' is matched as a single pattern.\n",
    "\n",
    "- Hence, the string 'ff0000' and '6a5acd' will be replaced with a whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1749725943959,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "9G2JPQTs7p6d",
    "outputId": "e5edeac8-36be-4f37-f041-ad962dab65dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TYR45bv7rzR"
   },
   "source": [
    "- The character '#' is retained and a whitespace between '#ff0000' and '#6a5acd' is retained since it doesn't match with the given pattern\n",
    "\n",
    "- Hence, the length of `cleaned_string` is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJll6RKzKNze"
   },
   "source": [
    "- The above review doesn't contain any digits.\n",
    "- Hence, the characters in the range a-f and A-F has been replaced with a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTR6C-zLHBn4"
   },
   "source": [
    "- Until now, we have been cleaning individual reviews one by one. While this is helpful, it can be time-consuming for larger number of reviews.\n",
    "\n",
    "- To make our process faster and easier, we want to clean all reviews in the DataFrame at once instead of handling them individually.\n",
    "\n",
    "- By using the ***apply*** function in Pandas, we can quickly apply our cleaning function, ***remove_special_characters***, to every review in the DataFrame in one go.\n",
    "\n",
    "- We will define the ***remove_special_characters*** function to remove special characters from the text. Then, we will apply this function to the review column, ensuring all reviews are clean and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1749725943978,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "mGR2c6dCvT-Q"
   },
   "outputs": [],
   "source": [
    "# defining a function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    # Defining the regex pattern to match non-alphanumeric characters\n",
    "    pattern = '[^A-Za-z0-9]+'\n",
    "\n",
    "    # Finding the specified pattern and replacing non-alphanumeric characters with a blank string\n",
    "    new_text = ''.join(re.sub(pattern, ' ', text))\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DftSZK9yQ74"
   },
   "source": [
    "### **Lowercasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btbl4O1tIpW1"
   },
   "source": [
    "<h2>Why is Lowercasing Important in Text Preprocessing?</h2>\n",
    "\n",
    "- It ensures that all words are in the same format, which helps maintain consistency across the dataset.\n",
    "  - This means \"Dog\" and \"dog\" are treated as the same word.\n",
    "\n",
    "- Converting text to lowercase simplifies the data, making it easier to process and analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eiMJHNoJI0t"
   },
   "source": [
    "<h2>How to Implement Lowercasing?</h2>\n",
    "\n",
    "- The `lower()` method is a built-in string method in Python that converts all uppercase characters in a string to lowercase.\n",
    "- This is useful for standardizing text data.\n",
    "\n",
    "<p><strong>Example:</strong></p>\n",
    "\n",
    "<pre>\n",
    "input_string = \"Hello, World!\"\n",
    "\n",
    "lowercased_string = input_string.lower()\n",
    "\n",
    "print(lowercased_string)\n",
    "</pre>\n",
    "\n",
    ">**Output** : hello, world!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749725947415,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "f2lVK2_Ulcp8",
    "outputId": "da16f65d-229a-4ab7-defc-c9c905b6967f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox\n"
     ]
    }
   ],
   "source": [
    "string = \"The Quick Brown Fox\"\n",
    "\n",
    "lowercased_string = string.lower()\n",
    "\n",
    "print(lowercased_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdm9ScKJK3l5"
   },
   "source": [
    "- As we can see, the characters in the `string` have been converted to lowercase.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GT_2v-KKtog"
   },
   "source": [
    "- Until now, we have been converting text to lowercase for individual reviews one by one. While this method works, it can be inefficient when dealing with a larger number of reviews.\n",
    "\n",
    "- To streamline our process, we want to convert all reviews in the DataFrame to lowercase at once instead of handling each one separately.\n",
    "\n",
    "- By using the `str.lower()` method in Pandas, we can efficiently apply the lowercase transformation to every review in the DataFrame in a single operation.\n",
    "\n",
    "- We will apply the `str.lower()` method to the review column, ensuring that all reviews are standardized and ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLoWwpxzylZH"
   },
   "source": [
    "### **Removing extra whitespace**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14sbXM3FLRQC"
   },
   "source": [
    "<h2>Why is Removing Extra Spaces Important in Text Preprocessing?</h2>\n",
    "\n",
    "- Removing extra spaces ensures uniformity in the text, making it easier to analyze and process.\n",
    "\n",
    "- Extra spaces can unnecessarily increase the size of the text data. By eliminating them, the overall storage requirements are reduced, leading to more efficient data handling and processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZcp_UwnLRQE"
   },
   "source": [
    "<h2>How to Implement Lowercasing?</h2>\n",
    "\n",
    "- The `strip()` method is a built-in string method in Python that removes leading and trailing whitespace from a string.\n",
    "- This is useful for cleaning up user input and ensuring consistent formatting in text data.\n",
    "\n",
    "**Example:**\n",
    "<pre>\n",
    "input_string = \"Hello, World! \"\n",
    "\n",
    "stripped_string = input_string.strip()\n",
    "\n",
    "print(stripped_string)\n",
    "</pre>\n",
    "\n",
    "> **Output :** Hello, World!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749725947659,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "1CjhS2IqlofD",
    "outputId": "d31ec7fd-f8c4-46ba-cad2-5cf196171ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "johan@gmail.com\n"
     ]
    }
   ],
   "source": [
    "string = \" johan@gmail.com \"\n",
    "\n",
    "stripped_string = string.strip()\n",
    "\n",
    "print(stripped_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEbwxVoAL3Id"
   },
   "source": [
    "- As expected, the trailing and leading whitespace has been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJBphEGuMZLS"
   },
   "source": [
    "- As expected, the leading whitespace has been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKQV2RZoLRQG"
   },
   "source": [
    "- Until now, we have been removing leading and trailing whitespace from individual reviews one by one. While this method is effective, it can be time-consuming when working with a large number of reviews.\n",
    "\n",
    "- To make our process more efficient, we want to remove extra spaces from all reviews in the DataFrame simultaneously instead of handling each one separately.\n",
    "\n",
    "- By utilizing the ***str.strip()*** method in Pandas, we can easily eliminate leading and trailing whitespace from every review in the DataFrame in a single operation.\n",
    "\n",
    "- We will apply the ***str.strip()*** method to the review column, ensuring that all reviews are cleaned and formatted consistently for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwVOVENFz9fJ"
   },
   "source": [
    "### **Removing stopwords**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddYQH3ef0AUj"
   },
   "source": [
    "<h2>Why is Removing Stop Words Important?<h2>\n",
    "\n",
    "- Stop words are common words (like \"and,\" \"the,\" and \"is\") that are often excluded from text analysis because they add little meaning to the content.\n",
    "\n",
    "- Excluding frequently occurring words helps emphasize the more significant terms in the text, improving analysis quality.\n",
    "\n",
    "- Removing pronouns and articles, commonly categorized as stop words, minimizes irrelevant information, allowing algorithms to better identify patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI4bg4EGQM5K"
   },
   "source": [
    "<h2>How to implement stop word removal?</h2>\n",
    "\n",
    "- Start by using a pre-defined list of stop words to identify common words that can be excluded from our analysis.\n",
    "\n",
    "- Downloading a stop words dataset ensures we have an updated collection of these words for accurate filtering.\n",
    "\n",
    "- As the text data grows, manually removing stop words can become tedious and inefficient.\n",
    "\n",
    "- Implementing an automated method to filter out stop words saves time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3hi9V3HNl7O"
   },
   "source": [
    "- NLTK (Natural Language Toolkit) is a Python library designed for working with human language data (text) and provides tools for various natural language processing tasks.\n",
    "\n",
    "- NLTK is widely used in academic and research settings, supported by an active community that contributes to its development and documentation, making it a valuable resource for learning and experimentation in NLP.\n",
    "\n",
    "- It is imported using the statement `import nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 7131,
     "status": "ok",
     "timestamp": 1749725954889,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "W48xWVI5NwVC"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZErYrs2RFoU"
   },
   "source": [
    "- NLTK has a module called stopwords that provides a list of common stop words based on the English language.\n",
    "\n",
    "- This list includes frequently used words that typically do not add significant meaning to text analysis.\n",
    "\n",
    "- We can download this stop words list using the statement `nltk.download('stopwords')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1749725955022,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "d8MVsWRLOGdi",
    "outputId": "d129a3db-db81-4981-9094-510724a62d17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vishalkhapre/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHgjFCmzOJr2"
   },
   "source": [
    "- Once we have downloaded the list, we can use the `corpus` module from `nltk` to load the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749725955028,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "1oLN35jRORhQ"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKEQCwrNOT_r"
   },
   "source": [
    "- To access the stopwords in the english language, we can use the `words` method from the stopwords module and pass 'english' as the argument.\n",
    "\n",
    "- We will list out the first 10 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1749725955044,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "b-duQjJ5Qzfq",
    "outputId": "8c49a3c4-d7ee-4015-950b-e649a14a47f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07xqkA3dRd7z"
   },
   "source": [
    "Using the NLTK stop words list, we can filter reviews by keeping only the words not in this list, allowing us to focus on meaningful content and enhance the quality of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mKCV0pfO5jM"
   },
   "source": [
    "- Suppose you have a list of words, and you are interested in converting it into a sentence as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749725955050,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "85gv_0QiPOsf"
   },
   "outputs": [],
   "source": [
    "list_of_words = [\"I\",\"love\",\"Text\",\"Preprocessing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY_ZOhmePUUD"
   },
   "source": [
    "- This is where the join method comes to rescue.\n",
    "\n",
    "  - The `join()` method takes all items in a list and joins them into one string with a seaparator.\n",
    "\n",
    "  - A string must be specified as the separator.\n",
    "\n",
    "  - **Syntax :** string.join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749725955062,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "1MD4X6IqPloX",
    "outputId": "21ceb4a5-b2cd-444b-d5b8-6eb99876db36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IspacelovespaceTextspacePreprocessing'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'space'.join(list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOaY1UQ1Pyt6"
   },
   "source": [
    "- As we can observe, the string 'space' has been added between each element in the list, thus forming a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1749725955108,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "Z9awtA-6P_Zm",
    "outputId": "8aefc843-4f39-42e3-c718-4b0568022ded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love Text Preprocessing'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhMK4BeHQCvw"
   },
   "source": [
    "- As we can observe, a whitespace has been added between each element in the list, thus forming a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXLZ-M2LUQTU"
   },
   "source": [
    "\n",
    "<h2>1. Splitting the Text</h2>\n",
    "<p>\n",
    "    The first step involves splitting the input <code>text</code> into individual words using the <code>split()</code> method. This method separates the text at each space and creates a list of words.\n",
    "</p>\n",
    "<pre><code>words = text.split()</code></pre>\n",
    "\n",
    "<h2>2. Removing Stop Words</h2>\n",
    "<p>\n",
    "    Next, we remove the English stop words from the list of words. We use a list comprehension to iterate through each word in the <code>words</code> list and check if it is not present in the stop words list obtained from <code>stopwords.words('english')</code>.\n",
    "</p>\n",
    "<pre><code>[word for word in words if word not in stopwords.words('english')]</code></pre>\n",
    "\n",
    "<h2>3. Creating the New Text</h2>\n",
    "<p>\n",
    "    Finally, the remaining words (those not in the stop words list) are joined back together into a single string using the <code>join()</code> method. This creates a new text string that contains only the meaningful words.\n",
    "</p>\n",
    "<pre><code>new_text = ' '.join([word for word in words if word not in stopwords.words('english')])</code></pre>\n",
    "\n",
    "<h2>4. Result</h2>\n",
    "<p>\n",
    "    The resulting <code>new_text</code> variable now holds the filtered text, free of common English stop words, which allows for a more relevant analysis of the content.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749725955121,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "pQFSIwLhVIPk",
    "outputId": "64fe380a-23b6-46c3-d407-1ee6c82f9455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog.\n",
      "The quick brown fox jumps lazy dog.\n"
     ]
    }
   ],
   "source": [
    "string = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "words = string.split(' ')\n",
    "\n",
    "new_text = ' '.join([word for word in words if word not in stopwords.words('english')])\n",
    "\n",
    "print(string)\n",
    "\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q450TQ2RQMOs"
   },
   "source": [
    "- As we can observe, the stopwords have been removed.\n",
    "- Additionally, we can note that the stopwords are 'over' and 'the', as they are not present in `new_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749725955134,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "PnaYor_tl0Gn",
    "outputId": "e53df659-923f-4277-b1ac-b57c6cd3355c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In order to succeed, you must first believe that you can.\n",
      "In order succeed, must first believe can.\n"
     ]
    }
   ],
   "source": [
    "string = \"In order to succeed, you must first believe that you can.\"\n",
    "\n",
    "words = string.split(' ')\n",
    "\n",
    "new_text = ' '.join([word for word in words if word not in stopwords.words('english')])\n",
    "\n",
    "print(string)\n",
    "\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijUL6rI8QezU"
   },
   "source": [
    "- As we can observe, the stopwords have been removed.\n",
    "- Additionally, we can note that the stopwords are 'to', 'you' and 'that', as they are not present in `new_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9vTluh-U3sm"
   },
   "source": [
    "- Until now, we have been removing stop words from individual reviews one by one. While this method is effective, it can be inefficient when processing a larger number of reviews.\n",
    "\n",
    "- To streamline our process, we want to remove stop words from all reviews in the DataFrame at once instead of handling each one separately.\n",
    "\n",
    "- By defining a function called ***remove_stopwords*** using the NLTK library, we can efficiently apply the stop word removal to every review in the DataFrame in a single operation.\n",
    "\n",
    "  - This function splits the text into separate words, removes English language stop words, and then joins the remaining words back into a single string, ensuring that all reviews are cleaned and ready for analysis.\n",
    "\n",
    "- To implement this, we will apply the ***remove_stopwords*** function to the review column in our DataFrame using the Pandas ***apply()*** method, allowing us to filter out common stop words from each review and enhance the quality of our text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1749725955181,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "Zof2x5co2X8g"
   },
   "outputs": [],
   "source": [
    "# defining a function to remove stop words using the NLTK library\n",
    "def remove_stopwords(text):\n",
    "    # Split text into separate words\n",
    "    words = text.split()\n",
    "\n",
    "    # Removing English language stopwords\n",
    "    new_text = ' '.join([word for word in words if word not in stopwords.words('english')])\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN9S84Sj2om2"
   },
   "source": [
    "### **Stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7gAf4rJchR2"
   },
   "source": [
    "<h2>Why is Stemming Important?</h2>\n",
    "\n",
    "- Stemming transforms different forms of a word (e.g., \"running,\" \"ran,\" \"runs\") into a single root (e.g., \"run\"), making data more uniform.\n",
    "\n",
    "- Fewer unique words mean simpler data, which helps in processing and analyzing text more efficiently.\n",
    "\n",
    "- It helps in identifying key topics and sentiments by focusing on the core meaning of words rather than their variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urpKFz7C-D55"
   },
   "source": [
    "<h2>How to implement?</h2>\n",
    "\n",
    "The Porter Stemmer is one of the widely-used algorithms for stemming, and it shorten words to their root form by removing suffixes.\n",
    " - This is particularly useful in NLP tasks where you want to analyze the underlying meaning of text without being misled by different grammatical forms of the same word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5tuAxb9SQkN"
   },
   "source": [
    "NLTK module supports Porter Stemmer algorithm.\n",
    "\n",
    "Before proceeding, we need to download the `wordnet` database.\n",
    " - WordNet is a large lexical database of English words that groups words into sets of synonyms called synsets, providing definitions and semantic relationships between them.\n",
    " - By using nltk.download('wordnet'), we can download the WordNet dataset directly into their NLTK environment, enabling easy access to its rich linguistic resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1749726182069,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "zimvC7UUSKKK",
    "outputId": "b5bdd1df-13f9-475e-857a-7bb0afcaca77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vishalkhapre/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BcfyM1ESz9B"
   },
   "source": [
    "Next, we can import the PorterStemmer module from `stem.porter` module available in the `nltk` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749726182079,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "bDyKJIIDSNPT"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVRbN7HWezPL"
   },
   "source": [
    "Creating an instance of the Porter Stemmer class, which is used to stem words by reducing them to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749726182083,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "ZHeywVxVehUQ"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBwj08awe00X"
   },
   "source": [
    "Specifying the input word that needs to be stemmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749726182091,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "fJVLxbyVejnt"
   },
   "outputs": [],
   "source": [
    "word = 'Running'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THisq_43e9v6"
   },
   "source": [
    "Applying the stemming process to the input word (in this case, 'Running'), and assigns the resulting stemmed form to the variable stemmed_word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749726182094,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "CkgAwUFielUo"
   },
   "outputs": [],
   "source": [
    "stemmed_word = ps.stem(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGzC5SKFfGc3"
   },
   "source": [
    "Displaying the input word and its stemmed form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1749726182206,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "IN2ISpC7entk",
    "outputId": "344d1ea5-a5b2-481f-cea4-8d73258920bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "print(word)\n",
    "print(stemmed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1749726182223,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "dcZIDwDnmBlI",
    "outputId": "ae75817f-7127-4691-e45d-c42acc5e750e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analzi\n"
     ]
    }
   ],
   "source": [
    "word = 'Analzying'\n",
    "\n",
    "stemmed_word = ps.stem(word)\n",
    "\n",
    "print(stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2aIEjs-Q1PB"
   },
   "source": [
    "- Here, we can note that the stemmed word is 'analzi' . But, the correct root word should be 'analyze'.\n",
    "\n",
    "- The reason is the Porter Stemmer uses a set of rules to strip suffixes from words.\n",
    "  - Its algorithm may not always produce linguistically correct stems, focusing instead on reducing words to their root forms based on pattern matching.\n",
    "\n",
    "- The specific rules for removing suffixes may lead to unusual results.\n",
    "  - For example, the removal of \"-ing\" from \"Analyzing\" can result in \"Analyz,\" which, combined with its handling of consonant patterns, can lead to \"analzi.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KpZx6nFfPED"
   },
   "source": [
    "- Until now, we have been applying stemming to individual words one by one. While this method is effective, it can be inefficient when processing larger texts or multiple reviews.\n",
    "\n",
    "- To streamline our process, we want to apply stemming to all words in a given text at once instead of handling each word separately.\n",
    "\n",
    "- By defining a function called ***apply_porter_stemmer*** using the NLTK library, we can efficiently apply the Porter stemming algorithm to every word in the text in a single operation.\n",
    "\n",
    "  - This function splits the input text into separate words, applies the Porter Stemmer to each word, and then joins the stemmed words back into a single string, ensuring that the text is uniformly stemmed and ready for further analysis.\n",
    "- To implement this, we will call the ***apply_porter_stemmer*** function for our text data, allowing us to reduce words to their root forms and enhance the quality of our text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749726182249,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "g2Nv5egY25SY"
   },
   "outputs": [],
   "source": [
    "# Loading the Porter Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# defining a function to perform stemming\n",
    "def apply_porter_stemmer(text):\n",
    "    # Split text into separate words\n",
    "    words = text.split()\n",
    "\n",
    "    # Applying the Porter Stemmer on every word of a message and joining the stemmed words back into a single string\n",
    "    new_text = ' '.join([ps.stem(word) for word in words])\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3F-popAzw8p"
   },
   "source": [
    "# **Text Vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iry8Eb8rnzKm"
   },
   "source": [
    "<h2>Why is Text Vectorization Important?</h2>\n",
    "\n",
    "- It transforms words and sentences into numerical formats that mathematical algorithms can understand, making it essential for processing text data.\n",
    "\n",
    "- By representing text as vectors, it helps capture important patterns and relationships in the data, leading to better insights and analysis in text-related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5Q5legzRsUG"
   },
   "source": [
    "<p><h3>Definition:</h3> A document-term matrix is a mathematical representation of a collection of documents, where each document is represented as a row, and each unique word (or term) across all documents is represented as a column. The cells in the matrix contain values that indicate the frequency or presence of the corresponding word in the corresponding document.</p>\n",
    "\n",
    "<p><h3>Usage in Text Preprocessing:</h3> The document-term matrix is essential in text preprocessing as it converts unstructured text data into a structured numerical format. This transformation allows for efficient analysis and processing of textual information. By representing documents as matrices, it facilitates the extraction of important features and patterns, making it easier to prepare text data for further analysis and understanding.</p>\n",
    "\n",
    "<p><h3>Example:</h3></p>\n",
    "<p>Consider three short documents:</p>\n",
    "<ul>\n",
    "<li>Document 1: \"I love programming\"</li>\n",
    "<li>Document 2: \"Programming is fun\"</li>\n",
    "<li>Document 3: \"I love fun programming\"</li>\n",
    "</ul>\n",
    "\n",
    "<p><h3>Steps to Create the Document-Term Matrix:</h3></p>\n",
    "\n",
    "<li>Convert all text to lowercase:\n",
    "<ul>\n",
    "<li>Document 1: \"i love programming\"</li>\n",
    "<li>Document 2: \"programming is fun\"</li>\n",
    "<li>Document 3: \"i love fun programming\"</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>Identify all unique words across the documents and sort it:\n",
    "<ul>\n",
    "<li>fun , is , love , programming</li>\n",
    "</ul>\n",
    "</li>\n",
    "    \n",
    "<li>Count the occurrences of each word in each document:\n",
    "<ul>\n",
    "<li>Document 1:\n",
    "<ul>\n",
    "<li>\"fun\": 0</li>\n",
    "<li>\"is\": 0</li>\n",
    "<li>\"love\": 1</li>\n",
    "<li>\"programming\": 1</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Document 2:\n",
    "<ul>\n",
    "<li>\"fun\": 1</li>\n",
    "<li>\"is\": 1</li>\n",
    "<li>\"love\": 0</li>\n",
    "<li>\"programming\": 1</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Document 3:\n",
    "<ul>\n",
    "<li>\"fun\": 1</li>\n",
    "<li>\"is\": 0</li>\n",
    "<li>\"love\": 1</li>\n",
    "<li>\"programming\": 1</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "\n",
    "<li>Form a matrix using the counts, where each row represents a document and each column represents a unique word:</li><br>\n",
    "\n",
    "<table border=\"1\" cellspacing=\"0\" cellpadding=\"12\" align=\"center\" rules=\"all\" frame=\"box\" width=\"80%\" style=\"font-size: 20px; text-align: center;\">\n",
    "<thead>\n",
    "<tr bgcolor=\"#ADD8E6\">\n",
    "<th style=\"color: white;\">Document</th>\n",
    "<th style=\"color: white;\">fun</th>\n",
    "<th style=\"color: white;\">is</th>\n",
    "<th style=\"color: white;\">love</th>\n",
    "<th style=\"color: white;\">programming</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr bgcolor=\"#f2f2f2\">\n",
    "<td>Document 1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Document 2</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "<tr bgcolor=\"#f2f2f2\">\n",
    "<td>Document 3</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0wXmlWQbBpL"
   },
   "source": [
    "Creating the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749726205655,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "BFRh05KRVp4B"
   },
   "outputs": [],
   "source": [
    "Document_1 = \"I love programming\"\n",
    "Document_2 = \"programming is fun\"\n",
    "Document_3 = \"i love fun programming\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4T-YtcmbEVi"
   },
   "source": [
    "Appending all the documents to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749726205662,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "aQGQEqnEVznT"
   },
   "outputs": [],
   "source": [
    "list_of_docs = [Document_1,Document_2,Document_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpgOSY-GT5FC"
   },
   "source": [
    "- To implement this BoW representation, `sklearn` offers a class to work with called `Countvectorizer`\n",
    "\n",
    "- It is available in the `feature_extraction.text` module\n",
    "\n",
    "- It is imported using the statement `from sklearn.feature_extraction.text import CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1749726205848,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "TN1uMoKUT5qW"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtD0KDvobMPR"
   },
   "source": [
    "**`CountVectorizer`**:\n",
    "\n",
    "- This is a tool from `sklearn.feature_extraction.text` used to convert text documents into a matrix of token counts.\n",
    "- It creates a Bag of Words (BoW) representation of the text, where:\n",
    " - Each row represents a document.\n",
    " - Each column corresponds to a unique word (token) in the entire corpus.\n",
    " - The values in the matrix are the counts of each word's occurrence in the respective document\n",
    "\n",
    "**`fit_transform()`**:\n",
    "\n",
    "- The `fit_transform()` method performs both `fit()` and `transform()` in a single operation.\n",
    "- The `fit()` method learns the vocabulary from the provided documents (i.e., identifies the unique words).\n",
    "- The `transform()` method converts the documents into a sparse matrix, where:\n",
    "    - The matrix rows correspond to documents.\n",
    "    - The columns represent the words from the learned vocabulary.\n",
    "    - The values in the matrix are the word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749726205854,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "p0bWziYobLWb"
   },
   "outputs": [],
   "source": [
    "bow_vec = CountVectorizer()\n",
    "\n",
    "doc_matrix = bow_vec.fit_transform(list_of_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRv_c6APbsIC"
   },
   "source": [
    "Compressed Sparse Row format\n",
    "\n",
    "- It’s a way to store large matrices efficiently when most of the elements are zero.\n",
    "- Instead of storing every element, including the zeros, CSR compresses the data by only storing non-zero values and their positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749726205868,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "jdE8rphLV_fA",
    "outputId": "b9606752-9c8c-44c2-be2f-63eecf600a3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 8 stored elements and shape (3, 4)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749726205882,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "b3IpEYkKWB3e",
    "outputId": "575dede7-8603-42c0-f6db-6fd06c9f6b7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 0, 1, 1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting CSR to a numpy array\n",
    "doc_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSspaO2-UbFA"
   },
   "source": [
    "- As expected, the BoW representation matches with the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749726205896,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "0903xozaWIKZ",
    "outputId": "56bf602e-10d0-43ef-8991-e71e59a75f4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fun', 'is', 'love', 'programming'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns the list of unique words (tokens) extracted from the documents.\n",
    "bow_vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1749726205938,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "zLtSqgXpeIW6",
    "outputId": "2d1f31c8-8eaf-4167-fd50-2a734abe6979"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fun</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>programming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fun  is  love  programming\n",
       "0    0   0     1            1\n",
       "1    1   1     0            1\n",
       "2    1   0     1            1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to a pandas dataframe\n",
    "pd.DataFrame(doc_matrix.toarray(),columns=bow_vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U1stbKvcge6"
   },
   "source": [
    "- The *`max_features`* parameter in CountVectorizer limits the number of words (or tokens) used to create the vocabulary.\n",
    "- This helps when dealing with large datasets by keeping only the most important or frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1749726207120,
     "user": {
      "displayName": "Harish R",
      "userId": "16560730339059888072"
     },
     "user_tz": -330
    },
    "id": "N6QlX2WYzw8s",
    "outputId": "f8333ea4-1659-4c15-f7bb-6a073cfbbfb2"
   },
   "outputs": [],
   "source": [
    "# Initializing CountVectorizer with top 1000 words\n",
    "bow_vec = CountVectorizer(max_features = 2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH77U4ukBiCe"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bbEN80qLTOk"
   },
   "source": [
    "- We used different text processing techniques to clean the raw text data.\n",
    "\n",
    "- We then vectorized the cleaned text data using Bag of Words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2Lw8akCLT9c"
   },
   "source": [
    "<font size=6 color='blue'>Power Ahead</font>\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lKDOBv45zw8C",
    "wVldHvLCgnr9",
    "0Wiey7tkgz8P",
    "xptjKJz-_sYZ",
    "0GsZAWm0BiCQ",
    "ckwD7uwlsZwm",
    "mhzSVF82YYri",
    "62xkzNTFYmyq",
    "MUGy2CBnZa6g",
    "nZdNFg-5Zmiz",
    "2DftSZK9yQ74",
    "hLoWwpxzylZH",
    "c3F-popAzw8p",
    "wH77U4ukBiCe"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
